<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Ana Stoica Portfolio</title>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, user-scalable=no"
    />
    <link rel="stylesheet" href="../css/main.css" />
    <noscript
      ><link rel="stylesheet" href="../css/noscript.css"
    /></noscript>
  </head>
  <body class="is-preload" style="background-image: url('../../images/bg.jpg')">
    <!-- Wrapper -->
    <div id="wrapper">
      <!-- Intro -->
      <article id="intro">
        <h2 class="major">Correlation and Regression</h2>
          <h3>Formative Activity</h3>
          <h4 style="color: #9af8a3">
            Covariance Pearson Correlation
          </h4>
          <img src="../../images/module3-unit3-exercise1.png" alt="Covariance Pearson Correlation" width="500" height="600"/>
          <img src="../../images/module3-unit3-exercise1.1.png" alt="Covariance Pearson Correlation" width="500" height="500"/>
          <p>
            In order to observe how changes in data points impact correlation, I have manipulated data1 by adding a higher standard deviation of + 50, which shifts all values upward, while lowering the Pearson correlation. This change will result in a lower correlation, since data2 becomes less dependent on data1.
          </p>
          
          <br />

          <img src="../../images/module3-unit3-exercise1.2.png" alt="Covariance Pearson Correlation" width="500" height="600"/>
          <img src="../../images/module3-unit3-exercise1.3.png" alt="Covariance Pearson Correlation" width="500" height="500"/>
          <p>
           I have experimented by using the negative of data1 in order to invert the direction of the relationship. This change will lead to a strong negative Pearson correlation. 
          </p>
          
          <br />
          <h4 style="color: #9af8a3">
            Linear Regression
          </h4>
          <img src="../../images/module3-unit3-exercise2.png" alt="Linear Regression" width="900" height="500"/>
          <img src="../../images/module3-unit3-exercise2.1.png" alt="Linear Regression" width="500" height="400"/>
          <p>
            I have manipulated the x and y values in order to see how different relationships change and ultimately affect the regression line and correlation. By replacing x with a list of numbers that increase by 1 each step and y with twice for each corresponding x value, I have resulted in an example of a perfect linear relationship.
          </p>

          <br />

          <h4 style="color: #9af8a3">
            Multiple Linear Regression
          </h4>
          <img src="../../images/module3-unit3-exercise3.png" alt=" Multiple Linear Regression" width="600" height="500"/>
          <img src="../../images/module3-unit3-exercise3.1.png" alt=" Multiple Linear Regression" width="600" height="400"/>
          <p>
            The following dataset includes three variables: Weight, Volume, and CO2 emissions. By adding a new set of values, I'm looking at how data directly impacts the regression coefficients. In this example, Weight and Volume increase proportionally with the CO2 level. The increases are proportional and consistent, implying a strong, linear, positive relationship between both Weight and CO2, and Volume and CO2.
          </p>

          <br />

          <h4 style="color: #9af8a3">
            Polynomial Regression
          </h4>
          <img src="../../images/module3-unit3-exercise4.png" alt=" Polynomial Regression" width="700" height="300"/>
          <img src="../../images/module3-unit3-exercise4.1.png" alt=" Polynomial Regression" width="700" height="400"/>
          <img src="../../images/module3-unit3-exercise4.2.png" alt=" Polynomial Regression" width="1150" height="300"/>
          <br />
          <img src="../../images/module3-unit3-exercise4.3.png" alt=" Polynomial Regression" width="1100" height="300"/>
          <img src="../../images/module3-unit3-exercise4.4.png" alt=" Polynomial Regression" width="500" height="400"/>
          <p>
            This example shows how a single outlier can cause severe distortion in a polynomial regression model. The dataset contains x values ranging from 1 to 10, as well as matching y values ranging from 10 to 90 until the last point, where y = 300 introduces a significant outlier. While the first 9 data points show a clear linear trend, the outlier at x = 10 leads the regression curve to bend dramatically upward near the end. This creates a skewed model that no longer adequately captures the overall pattern of the data.
          </p>
        </article>
      </div>   
    <!-- Scripts -->
    <script src="../js/jquery.min.js"></script>
    <script src="../js/browser.min.js"></script>
    <script src="../js/breakpoints.min.js"></script>
    <script src="../js/util.js"></script>
    <script src="../js/main.js"></script>
  </body>
</html>
